{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca55913c-e34c-4669-bf3c-2514c5f521c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de097ef4-f312-4b82-a19e-830501506024",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29c925af-4792-4666-9120-769700575d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 612 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = training_generator.flow_from_directory(\n",
    "    'training_data',\n",
    "     target_size = (64,64),\n",
    "     batch_size = 32,\n",
    "     class_mode = 'binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae13135-3530-4721-8594-a64cac65d960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "855165ad-1ce7-4cbf-a82d-142a8d44ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageDataGenerator(\n",
    "    rescale = 1./255    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f019de6-6e92-4499-bc37-a60f67821a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_data.flow_from_directory(\n",
    "    'test_data', \n",
    "     batch_size = 32,\n",
    "     target_size = (64,64), \n",
    "     class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21273006-f919-4e50-8012-6c9a640fcc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ripe_lemons': 0, 'unripe_lemons': 1}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4043215d-f758-4ff5-8927-e8433b19d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters =32 , kernel_size= 3, activation = 'relu' , input_shape = [64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bda7e68-413d-4149-9e8b-f7dc5eaa79b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxpooling layer\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2707580c-0dc6-4fd9-801b-48f138da589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional convolutionary and maxpooling layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters =32, kernel_size = 3, activation = 'relu' ))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f50fd12-48d9-4402-87b7-b668d9616102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding flattening layer\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "#added another aritificial layer \n",
    "cnn.add(tf.keras.layers.Dense(units = 128 , activation  ='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d4ab35c-fc79-4ebf-9c99-4ed8a6af7eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding output layer\n",
    "cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b47c853-557e-4168-bd5d-f1e48d720a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "cnn.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "511aa155-e292-4383-8ed0-e667d0819cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - accuracy: 0.5303 - loss: 0.7680 - val_accuracy: 0.6267 - val_loss: 0.6552\n",
      "Epoch 2/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.6713 - loss: 0.6313 - val_accuracy: 0.4867 - val_loss: 0.7440\n",
      "Epoch 3/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.6534 - loss: 0.6158 - val_accuracy: 0.6333 - val_loss: 0.6239\n",
      "Epoch 4/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.7655 - loss: 0.5239 - val_accuracy: 0.6800 - val_loss: 0.6232\n",
      "Epoch 5/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.8068 - loss: 0.4565 - val_accuracy: 0.7067 - val_loss: 0.6421\n",
      "Epoch 6/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.7664 - loss: 0.4820 - val_accuracy: 0.6667 - val_loss: 0.6523\n",
      "Epoch 7/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.8160 - loss: 0.4736 - val_accuracy: 0.6533 - val_loss: 0.6887\n",
      "Epoch 8/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.7924 - loss: 0.4718 - val_accuracy: 0.6867 - val_loss: 0.6710\n",
      "Epoch 9/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.7917 - loss: 0.4592 - val_accuracy: 0.6533 - val_loss: 0.6996\n",
      "Epoch 10/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.7945 - loss: 0.4596 - val_accuracy: 0.6600 - val_loss: 0.6815\n",
      "Epoch 11/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.7767 - loss: 0.4702 - val_accuracy: 0.6600 - val_loss: 0.6999\n",
      "Epoch 12/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.7734 - loss: 0.4864 - val_accuracy: 0.5533 - val_loss: 0.9086\n",
      "Epoch 13/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.7994 - loss: 0.4770 - val_accuracy: 0.6467 - val_loss: 0.7043\n",
      "Epoch 14/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.7902 - loss: 0.4737 - val_accuracy: 0.6400 - val_loss: 0.7992\n",
      "Epoch 15/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8202 - loss: 0.4178 - val_accuracy: 0.6667 - val_loss: 0.7110\n",
      "Epoch 16/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.7930 - loss: 0.4376 - val_accuracy: 0.6267 - val_loss: 0.7916\n",
      "Epoch 17/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.7976 - loss: 0.4404 - val_accuracy: 0.6200 - val_loss: 0.7877\n",
      "Epoch 18/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.8463 - loss: 0.3786 - val_accuracy: 0.6000 - val_loss: 0.8697\n",
      "Epoch 19/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.8323 - loss: 0.3753 - val_accuracy: 0.6600 - val_loss: 0.7453\n",
      "Epoch 20/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.8097 - loss: 0.4090 - val_accuracy: 0.6267 - val_loss: 0.7464\n",
      "Epoch 21/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8218 - loss: 0.4170 - val_accuracy: 0.6200 - val_loss: 0.9359\n",
      "Epoch 22/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8330 - loss: 0.4137 - val_accuracy: 0.6200 - val_loss: 0.8389\n",
      "Epoch 23/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.8087 - loss: 0.4052 - val_accuracy: 0.6267 - val_loss: 0.8765\n",
      "Epoch 24/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.8611 - loss: 0.3281 - val_accuracy: 0.6333 - val_loss: 0.8180\n",
      "Epoch 25/25\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.8332 - loss: 0.4156 - val_accuracy: 0.6467 - val_loss: 0.8688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2755b349d60>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit our data set\n",
    "cnn.fit(x = training_set,validation_data=test_set ,epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8880126-620b-4007-a4a5-d0687232869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84d31aac-3017-4168-a977-e4740e9aa964",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image.load_img('predictions/image1.webp', target_size =(64,64))\n",
    "image2 = image.load_img('predictions/image2.jpeg', target_size = (64,64))\n",
    "image3 = image.load_img('predictions/image3.jpeg', target_size =(64,64))\n",
    "image4 = image.load_img('predictions/image4.jpg', target_size =(64,64))\n",
    "image5 = image.load_img('predictions/image5.webp', target_size =(64,64))\n",
    "\n",
    "image6 = image.load_img('predictions/image7.jpg', target_size =(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec03d51b-cdc9-4c0f-a1e6-22fb7dc23d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image.img_to_array(image1)\n",
    "image2 = image.img_to_array(image2)\n",
    "image3 = image.img_to_array(image3)\n",
    "image4 = image.img_to_array(image4)\n",
    "image5 = image.img_to_array(image5)\n",
    "image6 = image.img_to_array(image6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5284a95b-39c0-4310-bac5-71983a5dcd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = np.expand_dims(image1 , axis = 0)\n",
    "image2 = np.expand_dims(image2, axis = 0)\n",
    "image3 = np.expand_dims(image3, axis = 0)\n",
    "image4 = np.expand_dims(image4, axis = 0)\n",
    "image5 = np.expand_dims(image5, axis = 0)\n",
    "image6 = np.expand_dims(image6, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88018266-c726-49a9-b240-b29d9384e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    }
   ],
   "source": [
    "result1 = cnn.predict(image1)\n",
    "result2 = cnn.predict(image2)\n",
    "result3 = cnn.predict(image3)\n",
    "result4 = cnn.predict(image4)\n",
    "result5 = cnn.predict(image5)\n",
    "result6 = cnn.predict(image6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32507294-c34d-42fe-99b0-f342b5ba6efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result1)\n",
    "print(result2)\n",
    "print(result3)\n",
    "print(result4)\n",
    "print(result5)\n",
    "print(result6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceecd0d-0513-4324-8b7c-529661986cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b6ae8-bf8f-4edd-8d28-943634526884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
